---
title: "An Analysis on Factors Affecting Placement Status"
subtitle: Ilan Lipsky, Samuel Sawyer Todd, Tran Tran
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---

```{r echo = F, results = 'hide', warning=F, message=F}
library(readr)
library(ggplot2)
library(dplyr)

# Load the dataset
df <- read_csv("Placement_Data_Full_Class.csv")

str(df)
head(df)
```

```{r echo = F, results = 'hide'}
# Removing unnecessary columns
college_df <- df %>% select(-sl_no)

# Cleaning up null data by replacing salary with 0
college_df$salary[is.na(college_df$salary)] <- 0

# One Hot Encoding
college_df <- college_df %>% 
  mutate(specialisation_Mkt_Fin = as.integer(specialisation == 'Mkt&Fin'),
         specialisation_Mkt_HR = as.integer(specialisation == 'Mkt&HR'),
         ssc_b_Others = as.integer(ssc_b == 'Others'),
         hsc_b_Others = as.integer(hsc_b == 'Others'),
         hsc_s_Arts = as.integer(hsc_s == 'Arts'),
         hsc_s_Commerce = as.integer(hsc_s == 'Commerce'),
         hsc_s_Science = as.integer(hsc_s == 'Science'),
         degree_t_Comm_Mgmt = as.integer(degree_t == 'Comm&Mgmt'),
         degree_t_Sci_Tech = as.integer(degree_t == 'Sci&Tech'),
         degree_t_Others = as.integer(degree_t == 'Others'))

college_df <- college_df %>% select(-c(specialisation, ssc_b, hsc_b, hsc_s, degree_t))

# Dictionary replacement
college_df$gender <- ifelse(college_df$gender == 'M', 0, 1)
college_df$workex <- ifelse(college_df$workex == 'No', 0, 1)
college_df$status <- ifelse(college_df$status == 'Not Placed', 0, 1)

```




## Introduction

The "Campus Recruitment" dataset is a collection of data that measures the academic performance of students from secondary to college. It also provides basic demographics such as their gender, work experience, salary offered, degree type, and placement status.

Variables: 

- sl_no: Serial number
- gender: Gender of the student (Male or Female)
- ssc_p: Secondary Education percentage (10th grade)
- ssc_b: Board of Education (Central/ Others)
- hsc_p: Higher Secondary Education percentage (12th grade)
- hsc_b: Board of Education (Central/ Others)
- hsc_s: Specialization in Higher Secondary Education (Science/ Commerce/Arts)
- degree_p: Degree Percentage
- degree_t: Undergraduate Degree Type (Sci&Tech/Comm&Mgmt/Other)
- workex: Work Experience (Yes/ No)
- etest_p: Employability test percentage (conducted by the college)
- specialisation: Post Graduate Specialization (Mkt&HR/Mkt&Fin)
- mba_p: MBA percentage
- status: Placement status (Not Placed/Placed)
- salary: Salary offered by corporate to candidates


The main question we are trying to answer using this dataset is:

What important factors influenced a candidate in getting recruited?

## What important factors influenced a candidate in getting recruited?

We will be using two different models and several graphs to answer this question and analyze our dataset. Namely, we will be using logistic regression and random forest. First, we will start with logistic regression and use a Stepwise algorithm to optimize the model. Afterward, we will start with random forest and use feature importance to optimize the model. Both models will be using placement status as a response variable to compare and contrast which predictors are significant for a candidate to be recruited.  

## 1. Logistic Regression Model (Tran Tran)

### 1.1 Model Equation and Background

First, we will build the model using all of the predictor variables except serial number and salary, because having a salary means the candidate has already been recruited and including it will cause the result to be interpret inaccurately.

Model equation: 

$log(\frac{p}{1-p})=\beta_0 + \beta_1 * ssc_p + \beta_2 * ssc_b + \beta_3*hsc_p+\beta_4*hsc_b+\beta_5*hsc_s+\beta_6*degree_p+\beta_7*degree_t+\beta_8*workex+\beta_9*etest_p+\beta_{10}*specialisation+\beta_{11}*mba_p+\beta_{12}*gender+\epsilon$

$\beta_8$ = {0 if no, 1 if yes}

$\beta_{12}$ = {0 if male, 1 if female}

Using this model equation we will look over which predictors are of significant importance using the optimization method mentioned previously. Logistic regression was used because the response variable is categorical with a binary outcome, placed or not placed. Another reason is that this model is less complex but still provides good interpretability, which aligns with the goal of answering the project question. Unfortunately, logistic regression is more sensitive to outliers and overfitting compared to more complex models like random forest. 

In regard to the outliers issue I have created multiple distribution plots for all of the continuous variables to see if it is a problem and luckily the outliers are very few to introduce a bias. Then for the overfitting possibility, by using the 80/20 split during training and 10 random subdivision this should not be an issue. 

### 1.2 Building Logistic Regression Model

First I will run a summary report on the model with all of the predictors except salary as reasoned previously. Here I will look over which predictors are statistically significant and I can see that ssc_p, hsc_p, degree_p, workex, and mba_p P-values are less than 0.05, indicating that it is significant to our response variable, the only one need further assessing is gender because its p-value is slightly higher than the common threshold.

```{r, echo=FALSE}
college_glm_1 <- glm(status ~ . -salary, data = college_df, family = "binomial", maxit = 1000)
summary(college_glm_1)
```

```{r echo = F, results = 'hide', warning = F, message = F}
library(ggplot2)
library(gridExtra)

library(ggplot2)
library(gridExtra)

# Gender Count
plot1 <- ggplot(df, aes(x = gender, fill = gender)) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +
  labs(x = 'Gender', y = 'Count') +
  scale_fill_brewer(palette = 'Pastel1') +
  coord_cartesian(clip = "off")  

# Placement Status and Work Experience
plot2 <- ggplot(df, aes(x = status, fill = workex)) +
  geom_bar(position = 'dodge') +
  geom_text(stat = 'count', aes(label = after_stat(count)), position = position_dodge(0.9), vjust = -0.5) +
  labs(x = 'Placement Status by Work Experience', y = 'Count') +
  scale_fill_brewer(palette = 'Pastel1') +
  coord_cartesian(clip = "off")  

# Placement Status
plot3 <- ggplot(df, aes(x = status, fill = status)) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +
  labs(x = 'Placement Status', y = 'Count') + 
  scale_fill_brewer(palette = 'Pastel1') +
  coord_cartesian(clip = "off")  

# Placement Status by Genders
plot4 <- ggplot(df, aes(x = status, fill = gender)) +
  geom_bar(position = 'dodge') +
  geom_text(stat = 'count', aes(label = after_stat(count)), position = position_dodge(0.9), vjust = -0.5) +
  labs(x = 'Placement Status by Genders', y = 'Count') +
  scale_fill_brewer(palette = 'Pastel1') +
  coord_cartesian(clip = "off") 

# Arrange the plots into a 2x2 
grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)


```

Looking over the count plots above, we can see that they match some of the assumptions that were found in the summary table. Placement status by genders for example, while at first seemingly skewed toward male students being favored, we have to remember the gender population in the dataset is 76 females vs 139 males, male students are nearly double compared to female students. 
The placement status by gender showed that there is bias against female students in proportion to the overall gender distribution in the dataset, and while it is not a large bias, I think it is still beneficial to include it in the final building process.

Now I will run the Stepwise algorithm which will progressively try to minimize the AIC and maximize the $R^2$ by removing and adding predictors to the model.  

```{r}
table = step(college_glm_1, trace = 0 )
table
```

The final result for the best optimization matched well with what we already saw through the summary table before running the step() function. With gender, ssc_p, hsc_p, degree_p, workex, and mba_p being the best predictors for the model, but we also see degree_t_Comm_Mgmt being the extra predictor in the result despite its high P-value. This could be because while it is not significant when combined with the initial all predictors run, it is in fact significant when we run with this selected group of predictors instead. 

### 1.3 Logistic Regression Results

The building process is finished, so I will now perform cross validation with 80% training and 20% testing sets. 

```{r}
set.seed(41)
test_error = numeric(10)

for (i in 1:10) {
  sample_indices = sample.int(n = nrow(college_df), size = floor(0.8 * nrow(college_df)), 
                              replace = FALSE)
  train = college_df[sample_indices,]
  test = college_df[-sample_indices,]

  college_glm = glm(status ~ gender + ssc_p + hsc_p + degree_p + workex 
                    + mba_p + degree_t_Comm_Mgmt,
                     data = train,
                     family = "binomial")

  college_pred = predict.glm(college_glm, newdata = test, type = "response")
  yhat = ifelse(college_pred < 0.5, 'Not Placed', 'Placed')

  conf.test = table(test$status, yhat)
  test_error[i] = (conf.test[1, 2] + conf.test[2, 1]) / nrow(test)
}
mean(test_error)
```
The result is quite promising, with an average test error rate of only 11.40% for the logistic regression model. This indicates that the model performs reasonably well in predicting the outcome for placement status 

```{r}
exams.glm2 = glm(status ~ gender + ssc_p + hsc_p + degree_p + workex 
                 + mba_p + degree_t_Comm_Mgmt,
                     data = train,
                     family = "binomial")
summary(exams.glm2)
```

Looking over all of the results, we can now answer the question: "What important factors influenced a candidate in getting recruited?". 
From the summary table, we can see that if your gender is male, with a higher Secondary Education percentage, Higher Secondary Education percentage, Degree percentage and you have work experience as well as pursuing a degree in Communication and Management then your odds of getting recruited increase. Interestingly, having a higher MBA percentage actually decreases the log-odds of getting hired. This I surmise might be due to a diminishing return issue, because in the specialization column, there are only two specialties for students going into post-grad, which are Marketing & Finance or Marketing & HR, both of which are not exactly required going into the field, unlike more STEM-focused fields. It could also be because while having a good MBA percentage is generally beneficial, there may be a point beyond which additional percentage points do not contribute significantly to getting hired. 
 
## 2. Random Forest Model (Samuel Sawyer Todd, Ilan Lipsky)

### 2.1 Model Equation and Background
Next we will build the Random Forest using all of the predictors variables except serial number and salary, because having a salary means the candidate is already recruited, and including it will cause the result to be an inaccurate interpretation.

Model equation:

$status\sim\ gender + ssc\_p + ssc\_b + hsc\_p + hsc\_b + hsc\_s + degree\_p + degree\_t + workex + etest\_p + specialisation + mba\_p$

Using this model equation we will look over which predictors are of significant importance using variable importance plot. Random Forest was used because it is more robust to overfitting compared to Logistical Regression. It combines predictions from multiple decision trees, providing a natural form of regularization. Additionally, it has a built-in feature importance measure, which enables the identification of key predictors in the model. However, Random Forest models are computationally intensive and may overfit to noise in training data if the number of trees is too high


### 2.2 Building Random Forest Model

After converting the binary values to factors to ensure compatibility with the random forest algorithm, we split the data set into training and testing sets using the same fixed seed that was used for our Logistical Regression.

```{r echo = F, results = 'hide', warning = F, message = F}
library(randomForest)
library(randomForestExplainer)
library(caret)
library(magrittr) 

# Convert binary variables to factors
college_df$gender <- as.factor(college_df$gender)
college_df$workex <- as.factor(college_df$workex)
college_df$status <- as.factor(college_df$status)

# Split the data into training and testing sets
set.seed(41)
sample_indices <- sample.int(n = nrow(college_df), size = floor(0.8 * nrow(-college_df)), replace = FALSE)
train_data <- college_df[sample_indices, ]
test_data <- college_df[-sample_indices, ]

```

We then utilize the randomForest function to train a random forest model in predicting admission status, excluding the "salary" variable, and then generate a Variable Importance Plot based on the model. 

```{r}
# Train random forest model
rf_model_importance <- randomForest(status ~ . -salary, data = college_df, importance = TRUE)

# Plot feature importance
varImpPlot(rf_model_importance, main = "Random Forest Feature Importance")
```
We can see in the MeanDecreaseGini plot graph of feature importance above that "ssc_p", "hsc_p", "degree_p", "mba_p", "etest_p", "workex", and "specialisation_Mkt_HR" are the most significant variables in predicting college admission status as they are factors of the steepest drop curve. 

Next, we rigorously test the trained Random Forest model by applying it to the designated test set, generating predictions that serve as a critical measure of its efficacy. To ensure consistency with the original status variable, the predicted values are converted into factors, maintaining alignment with the variable's distinct levels. We then use the above data from the feature importance plot to make a new model featuring only the most important factors, and we compare its confusion matrix on the test data to that of the overall Random Forest model. 

```{r}
# Train random forest model
rf_model_no_importance <- randomForest(status ~ . -salary, data = train_data, importance = TRUE)

# Make predictions on the test set
rf_pred <- predict(rf_model_no_importance, newdata = test_data)

# Convert predicted values to factors with the same levels as the original status variable
rf_pred <- factor(rf_pred, levels = levels(test_data$status))

# Confusion matrix
conf_matrix_rf <- confusionMatrix(data = rf_pred, reference = test_data$status)
print(conf_matrix_rf)

```

```{r}

# Train new forest model based on most important factors
rf_new_model_importance <- randomForest(status ~ ssc_p + hsc_p + degree_p + mba_p + etest_p + workex + specialisation_Mkt_HR + gender, data = train_data, importance = TRUE)

# Make predictions on the test set
rf_pred <- predict(rf_new_model_importance, newdata = test_data)

# Convert predicted values to factors with the same levels as the original status variable
rf_pred <- factor(rf_pred, levels = levels(test_data$status))

# Confusion matrix
conf_matrix_rf <- confusionMatrix(data = rf_pred, reference = test_data$status)
print(conf_matrix_rf)
```
Using only the 8 most important features, the accuracy rose by 2.33%, which both improves accuaracy and allows us to not have to spend the resources to track less important factors. We tried adding various extra factors to the second model to increase its accuracy, but found that after 8 important factors adding more did not provide enough of an accuracy boost to make their addition worth tracking. 

We attempted to use hyper-parameters for Random Forest optimization, however the default parameters were chosen as they are already optimized for the model. Therefore, we decided against updating the hyper-parameters. 

### 2.3 Random Forest Results

Lastly, the following code showcases a more robust assessment of model performance using the variables of significant importance and an iterative evaluation over 10 splits and calculations of the mean test prediction error. 

```{r}
set.seed(41)
test_errors <- numeric(10)

for (iteration in 1:10) {
  sample_indices <- sample.int(n = nrow(college_df), size = floor(0.8 * nrow(college_df)), replace = FALSE)
  train_data <- college_df[sample_indices, ]
  test_data <- college_df[-sample_indices, ]
  
  rf_model <- randomForest(status ~ ssc_p + hsc_p + degree_p + mba_p + etest_p + workex + specialisation_Mkt_HR + gender, data = train_data, importance = TRUE)
  
  rf_pred <- predict(rf_model, newdata = test_data)
  
  test_error <- mean(rf_pred != test_data$status)

  test_errors[iteration] <- test_error
  
}

mean_test_error <- mean(test_errors)
print(mean_test_error)
```
The resulting mean test prediction error is 0.1209302, which means the model performs reasonable well even after removing many of the less important variables.
```{r}
# Plot feature importance
varImpPlot(rf_new_model_importance, main = "Random Forest Feature Importance")
```
The analysis reveals that certain academic and personal attributes significantly influence a student's placement status. The most impactful factors, in descending order, include secondary education percentage, degree percentage, higher secondary education percentage, MBA percentage, employability test performance, work experience, gender, and specialization in management and human resources. Intriguingly, these factors are all continuous variables, suggesting a nuanced relationship between their numerical values and placement outcomes. This emphasis on continuous variables allows for a more fine-grained assessment of their influence. Potential explanations for this hierarchy may include the foundational importance of early education metrics, the relevance of advanced academic achievements, and the added value brought by practical experience and specialized skills. Moreover, gender-based and career-focused considerations further contribute to the nuanced dynamics influencing placement outcomes, emphasizing the multifaceted nature of the decision-making process in student placements.

## Bibliography

Roshan B. (April, 2020). Campus Recruitment. Retrieved September 30, 2023 from https://www.kaggle.com/datasets/benroshan/factors-affecting-campus-placement

## Conclusion

In this report, we used two models, Logistic Regression and Random Forest to analyze the dataset "Campus Recruitment" and determine which factors are significant for a candidate to be recruited. From the Logistic Regression, we can see that being male, possessing higher Secondary Education percentage, Higher Secondary Education percentage, Degree percentage, and having work experience while pursuing a degree in Communication and Management positively impact the likelihood of being recruited. Notably, a higher MBA percentage is associated with a decrease in the likelihood of recruitment, this could be due to many factors, one of which is potential diminishing return issue, wherein there may be a threshold beyond which additional percentage points contribute insignificantly to the recruitment prospects. Another is because there are only two specialties for students going into post-grad, which are Marketing & Finance or Marketing & HR, both of which are not exactly required going into the field, unlike more STEM-focused fields. 

Moving on to Random Forest, in descending order, the significant predictors for getting recruit include secondary education percentage, degree percentage, higher secondary education percentage, MBA percentage, employability test performance, work experience, gender, and specialization in management and human resources. //continue here 

//Now we compare then determine which factors determine placement status for both model


While both models did reasonably well in predicting the placement status for candidates, Logistic Regression is the better option for this dataset, due to its lower mean test prediction error of 11.40% vs Random Forest 12.09%. Also, given the relatively small size of the dataset, the simplicity of Logistic Regression proves advantageous both computationally and in terms of interpretation. Logistic Regression provides a straightforward breakdown of how each specific factor influences the likelihood of placement status and work well when you have a linear relationship. In contrast, Random Forest, resembling a diverse group of decision-makers, offers a collective prediction. While this ensemble approach is robust, understanding the impact of individual factors becomes more intricate. For our analysis, where clarity on individual contributions is crucial, the precision and transparency of Logistic Regression make it the preferred choice. 


